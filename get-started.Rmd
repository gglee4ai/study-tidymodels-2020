---
title: "Tidymodels: Get started"
date: 2020-05-20
output: 
  html_notebook: 
    toc: yes
---


# 1. Build a model

```{r}
#install.packages("tidymodels")
library(tidymodels)
library(readr)
```

```{r}
urchins <-
  read_csv("https://tidymodels.org/start/models/urchins.csv") %>%
  setNames(c("food_regime", "initial_volume", "width")) %>%
  mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High")))
urchins
```

```{r}
urchins %>%
  ggplot(aes(initial_volume, width, col = food_regime)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  scale_colour_viridis_d(option = "plasma", end = .7)
```

```{r}
lm_mod <- linear_reg() %>%
  set_engine("lm")
lm_mod
```

```{r}
lm_fit <- lm_mod %>%
  fit(width ~ initial_volume * food_regime, data = urchins)
lm_fit
```

```{r}
tidy(lm_fit)
```

```{r}
new_points <- expand.grid(
  initial_volume = 20, 
  food_regime = c("Initial", "Low", "High"))
new_points
```


```{r}
mean_pred <- predict(lm_fit, new_data = new_points)
mean_pred
```

```{r}
conf_int_pred <- predict(lm_fit,
                         new_data = new_points,
                         type = "conf_int")
conf_int_pred
```

```{r}
plot_data <- new_points %>%
  bind_cols(mean_pred) %>%
  bind_cols(conf_int_pred)

plot_data %>%
  ggplot(aes(food_regime)) +
  geom_point(aes(y = .pred)) +
  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper), width = .2) +
  labs(y = "urchin size")
```

```{r}
prior_dist <- rstanarm::student_t(df = 1)

set.seed(123)

bayes_mod <- 
  linear_reg() %>%
  set_engine("stan",
             prior_intercept = prior_dist,
             prior = prior_dist)

bayes_fit <-
  bayes_mod %>%
  fit(width ~ initial_volume * food_regime, data = urchins)

print(bayes_fit, digits = 5)
```

```{r}
tidy(bayes_fit, intervals = TRUE)
```

```{r}
new_points %>%
  bind_cols(predict(bayes_fit, new_data = new_points)) %>%
  bind_cols(predict(bayes_fit, new_data = new_points, type = "conf_int")) %>%
  ggplot(aes(food_regime)) +
  geom_point(aes(y = .pred)) +
  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper), width = .2) +
  labs(title = "Bayesian model with t(1) prior distribution")
```


# 2. Preprocess your data with recipes

```{r}
library(tidymodels)
library(nycflights13)
library(skimr)
```


```{r}
set.seed(123)

flight_data <- 
  flights %>% 
  mutate(
    # Convert the arrival delay to a factor
    arr_delay = ifelse(arr_delay >= 30, "late", "on_time"),
    arr_delay = factor(arr_delay),
    # We will use the date (not date-time) in the recipe below
    date = as.Date(time_hour)
  ) %>% 
  # Include the weather data
  inner_join(weather, by = c("origin", "time_hour")) %>% 
  # Only retain the specific columns we will use
  select(dep_time, flight, origin, dest, air_time, distance, 
         carrier, date, arr_delay, time_hour) %>% 
  # Exclude missing data
  na.omit() %>% 
  # For creating models, it is better to have qualitative columns
  # encoded as factors (instead of character strings)
  mutate_if(is.character, as.factor)
flight_data
```

```{r}
flight_data %>%
  count(arr_delay) %>%
  mutate(prop = n / sum(n))
```

```{r}
glimpse(flight_data)
```

```{r}
flight_data %>%
  skimr::skim(dest, carrier)
```

```{r}
set.seed(555)
data_split <- initial_split(flight_data, prop = 3/4)

train_data <- training(data_split)
test_data <- testing(data_split)
```

```{r}
flights_rec <-
  recipe(arr_delay ~ ., data = train_data) %>%
  update_role(flight, time_hour, new_role = "ID")
summary(flights_rec)
```

```{r}
flight_data %>%
  distinct(date) %>%
  mutate(numeric_date = as.numeric(date))
```

```{r}
test_data %>%
  distinct(dest) %>%
  anti_join(train_data)
```

```{r}
flights_rec <-
  recipe(arr_delay ~ ., data = train_data) %>%
  update_role(flight, time_hour, new_role = "ID") %>%
  step_date(date, features = c("dow", "month")) %>%
  step_holiday(date, holidays = timeDate::listHolidays("US")) %>%
  step_rm(date) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors())
summary(flights_rec)
```


```{r}
lr_mod <-
  logistic_reg() %>%
  set_engine("glm")
```

```{r}
flights_wflow <-
  workflow() %>%
  add_model(lr_mod) %>%
  add_recipe(flights_rec)
flights_wflow
```

```{r}
flights_fit <-
  flights_wflow %>%
  fit(data = train_data)
```

```{r}
flights_fit %>%
  pull_workflow_fit() %>%
  tidy()
```

```{r}
flights_fit %>%
  pull_workflow_prepped_recipe()
```



```{r}
predict(flights_fit, test_data)
```

```{r}
flights_pred <-
  predict(flights_fit, test_data, type = "prob") %>%
  bind_cols(test_data %>% select(arr_delay, time_hour, flight))
flights_pred
```


```{r}
flights_pred %>%
  roc_curve(truth = arr_delay, .pred_late) %>%
  autoplot()
```

```{r}
flights_pred %>%
  roc_auc(truth = arr_delay, .pred_late)
```




```{r}
flights_wflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  #add_recipe(lr_recipe) %>%
  add_formula(
    arr_delay ~ dep_time + origin + dest + air_time + distance + carrier + date
  )

flights_fit <-
  flights_wflow %>%
  fit(data = train_data)

flights_pred <-
  predict(flights_fit, test_data, type = "prob") %>%
  bind_cols(test_data %>% select(arr_delay))

flights_pred %>%
  roc_auc(truth = arr_delay, .pred_late)
```



# 3. Evaluate your model with resampling

```{r}
library(modeldata)
```

```{r}
data(cells, package = "modeldata")
cells
```

```{r}
cells %>%
  count(class) %>%
  mutate(prop = n / sum(n))
```

```{r}
set.seed(123)
cell_split <- initial_split(cells %>% select(-case), strata = class)
cell_train <- training(cell_split)
cell_test <- testing(cell_split)
```

```{r}
nrow(cell_train)
nrow(cell_train) / nrow(cells)
```

```{r}
cell_train %>%
  count(class) %>%
  mutate(prop = n / sum(n))

cell_test %>%
  count(class) %>%
  mutate(prop = n / sum(n))
```


```{r}
rf_mod <-
  rand_forest(trees = 1000) %>%
  set_engine("ranger") %>%
  set_mode("classification")
```


```{r}
set.seed(234)
rf_fit <-
  rf_mod %>%
  fit(class ~ ., data = cell_train)
```


```{r}
rf_training_pred <-
  predict(rf_fit, cell_train) %>%
  bind_cols(predict(rf_fit, cell_train, type = "prob")) %>%
  bind_cols(cell_train %>% select(class))
rf_training_pred
```

```{r}
rf_training_pred %>% 
  roc_auc(truth = class, .pred_PS)

rf_training_pred %>%
  accuracy(truth = class, .pred_class)
```


```{r}
rf_testing_pred <-
  predict(rf_fit, cell_test) %>%
  bind_cols(predict(rf_fit, cell_test, type = "prob")) %>%
  bind_cols(cell_test %>% select(class))
rf_testing_pred
```

```{r}
rf_testing_pred %>% 
  roc_auc(truth = class, .pred_PS)

rf_testing_pred %>% 
  accuracy(truth = class, .pred_class)
```

```{r}
set.seed(345)
folds <- vfold_cv(cell_train, v = 10)
folds
```

```{r}
rf_wf <-
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_formula(class ~ .)

set.seed(456)
rf_fit_rs <- 
  rf_wf %>% 
  fit_resamples(folds)
```


```{r}
collect_metrics(rf_fit_rs)
```

```{r}
rf_testing_pred %>%                   # test set predictions
  roc_auc(truth = class, .pred_PS)
rf_testing_pred %>%                   # test set predictions
  accuracy(truth = class, .pred_class)
```


# 4. Tune model parameters

```{r}
library(modeldata)
library(vip)
```

```{r}
data(cells, package = "modeldata")
cells
```

```{r}
set.seed(123)
cell_split <- initial_split(cells %>% select(-case), strata = class)
cell_train <- training(cell_split)
cell_test <- testing(cell_split)
```

```{r}
cell_train
cell_test
```

```{r}
tune_spec <-
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
tune_spec
```

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5)
tree_grid
```

```{r}
tree_grid %>%
  count(tree_depth)
```

```{r}
set.seed(234)
cell_folds <- vfold_cv(cell_train)
cell_folds
```

```{r}
cell_folds$splits[1]
```

```{r}
set.seed(345)
tree_wf <- workflow() %>%
  add_model(tune_spec) %>%
  add_formula(class ~ .)

tree_res <-
  tree_wf %>% 
  tune_grid(
    resamples = cell_folds,
    grid = tree_grid
  )
tree_res
```

```{r}
tree_res %>%
  collect_metrics()
```

```{r}
tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
```

```{r}
tree_res %>%
  show_best("roc_auc")
```

```{r}
best_tree <- tree_res %>%
  select_best("roc_auc")
best_tree
```

```{r}
final_wf <-
  tree_wf %>%
  finalize_workflow(best_tree)
final_wf
```

```{r}
final_tree <-
  final_wf %>%
  fit(data = cell_train)
final_tree
```

```{r}
library(vip)
final_tree %>%
  pull_workflow_fit() %>%
  vip()
```

```{r}
final_fit <-
  final_wf %>%
  last_fit(cell_split)

final_fit %>%
  collect_metrics()
```

```{r}
final_fit %>%
  collect_predictions() %>%
  roc_curve(class, .pred_PS) %>%
  autoplot()
```

```{r}
args(decision_tree)
```


# 5. A predictive modeling case study

```{r}
library(tidymodels)

library(readr)
library(vip)
```

```{r}
hotels <-
  read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%
  mutate_if(is.character, as.factor)
hotels
```

```{r}
glimpse(hotels)
```

```{r}
hotels %>%
  count(children) %>%
  mutate(prop = n / sum(n))
```

```{r}
set.seed(123)
splits <- initial_split(hotels, strata = children)
hotel_other <- training(splits)
hotel_test <- testing(splits)
```

```{r}
hotel_other %>%
  count(children) %>%
  mutate(prop = n/sum(n))
```

```{r}
hotel_test %>%
  count(children) %>%
  mutate(prop = n/sum(n))
```

```{r}
set.seed(234)
val_set <- validation_split(hotel_other,
                            strata = children,
                            prop = 0.80)
val_set
```

```{r}
lr_mod <-
  logistic_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")
```


```{r}
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")
lr_recipe <- 
  recipe(children ~ ., data = hotel_other) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date, holidays = holidays) %>% 
  step_rm(arrival_date) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())
lr_recipe
```

```{r}
lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```

```{r}
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
lr_reg_grid %>% top_n(-5)
lr_reg_grid %>% top_n(5)
```


```{r}
lr_res <- 
  lr_workflow %>% 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
lr_res
```


```{r}
lr_plot <- 
  lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())
lr_plot 
```


```{r}
top_models <-
  lr_res %>%
  show_best("roc_auc", n = 15) %>% 
  arrange(penalty)
top_models
```


```{r}
lr_best <- 
  lr_res %>% 
  collect_metrics() %>% 
  arrange(penalty) %>% 
  slice(12)
lr_best
#> # A tibble: 1 x 6
#>   penalty .metric .estimator  mean     n std_err
#>     <dbl> <chr>   <chr>      <dbl> <int>   <dbl>
#> 1 0.00137 roc_auc binary     0.881     1      NA

```

```{r}
lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)

```

```{r}
cores <- parallel::detectCores()
cores
```

```{r}
rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
  set_engine("ranger", num.threads = cores) %>%
  set_mode("classification")
rf_mod
```

```{r}
rf_recipe <-
  recipe(children ~ ., data = hotel_other) %>%
  step_date(arrival_date) %>%
  step_holiday(arrival_date) %>%
  step_rm(arrival_date)
rf_recipe
```

```{r}
rf_workflow <-
  workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(rf_recipe)
rf_workflow
```

```{r}
rf_mod %>%
  parameters()
```


```{r}
set.seed(345)
rf_res <-
  rf_workflow %>% 
  tune_grid(val_set,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```

```{r}
rf_res %>%
  show_best(metric = "roc_auc")
```

```{r}
autoplot(rf_res)
```

```{r}
rf_best <-
  rf_res %>%
  select_best(metric = "roc_auc")
rf_best
```

```{r}
rf_res %>%
  collect_predictions()
```



```{r}
rf_auc <-
  rf_res %>% 
  collect_predictions(parameters = rf_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Random Forest")
```


```{r}
bind_rows(rf_auc, lr_auc) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) +
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) +
  coord_equal() +
  scale_color_viridis_d(option = "plasma", end = .6)
```

```{r}
last_rf_mod <-
  rand_forest(mtry = 8, min_n = 7, trees = 1000) %>%
  set_engine("ranger", num.threads = cores, importance = "impurity") %>% 
  set_mode("classification")

last_rf_workflow <-
  rf_workflow %>%
  update_model(last_rf_mod)

set.seed(345)
last_rf_fit <-
  last_rf_workflow %>%
  last_fit(splits)
```

```{r}
last_rf_fit
```

```{r}
last_rf_fit %>%
  collect_metrics()
```

```{r}
last_rf_fit %>%
  pluck(".workflow", 1) %>%
  pull_workflow_fit() %>%
  vip(num_features = 20)
```

```{r}
last_rf_fit %>%
  collect_predictions() %>%
  roc_curve(children, .pred_children) %>%
  autoplot()
```


