---
title: "Tools for creating effective models"
output: html_notebook
date: 2020-11-25
---


```{r}
options(paged.print = FALSE, max.print = 100)
```


# 10 Resampling for evaluating performance

```{r}
library(tidymodels)
data(ames)

ames <- mutate(ames, Sale_Price = log10(Sale_Price))

set.seed(123)
ames_split <- initial_split(ames, prob = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)

ames_rec <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + 
           Latitude + Longitude, data = ames_train) %>%
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal()) %>% 
  step_interact( ~ Gr_Liv_Area:starts_with("Bldg_Type_") ) %>% 
  step_ns(Latitude, Longitude, deg_free = 20)

lm_model <- linear_reg() %>% set_engine("lm")

lm_wflow <- 
  workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(ames_rec)

lm_fit <- fit(lm_wflow, ames_train)
```


```{r}
rf_model <-
  rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("regression")

rf_wflow <-
  workflow() %>% 
  add_formula(
    Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type +
      Latitude + Longitude) %>% 
  add_model(rf_model)

rf_fit <- rf_wflow %>% fit(data = ames_train)
```


```{r}
estimate_perf <- function(model, dat) {
  cl <- match.call()
  obj_name <- as.character(cl$model)
  data_name <- as.character(cl$dat)
  data_name <- gsub("ames_", "", data_name)
  
  reg_metrics <- metric_set(rmse, rsq)
  
  model %>% 
    predict(dat) %>% 
    bind_cols(dat %>% select(Sale_Price)) %>% 
    reg_metrics(Sale_Price, .pred) %>% 
    select(-.estimator) %>% 
    mutate(object = obj_name, data = data_name)
}
```


```{r}
estimate_perf(rf_fit, ames_train)
estimate_perf(rf_fit, ames_test)
```


```{r}
estimate_perf(lm_fit, ames_train)
estimate_perf(lm_fit, ames_test)
```


```{r}
set.seed(55)
ames_folds <- vfold_cv(ames_train, v = 10)
ames_folds
```


```{r}
ames_folds$splits[[1]] %>% analysis() %>% dim()
```


```{r}
vfold_cv(ames_train, v = 10, repeats = 5)
```


```{r}
mc_cv(ames_train)
```


```{r}
set.seed(12)
val_set <- validation_split(ames_train, prop = 3/4)
val_set
```


```{r}
analysis(val_set$splits[[1]])
assessment(val_set$splits[[1]])
```


```{r}
bootstraps(ames_train, times = 5)$splits
```


```{r}
time_slices <-
  tibble(x = 1:365) %>% 
  rolling_origin(initial = 6 * 30, assess = 30, skip = 29, cumulative = FALSE)

data_range <- function(x) {
  summarize(x, first = min(x), last = max(x))
}

map_dfr(time_slices$splits, ~ analysis(.x) %>% data_range())

map_dfr(time_slices$splits, ~ assessment(.x) %>% data_range())
```


```{r}
keep_pred <- control_resamples(save_pred = TRUE)

set.seed(130)
rf_res <- 
  rf_wflow %>% 
  fit_resamples(resamples = ames_folds, control = keep_pred)
rf_res
```


```{r}
collect_metrics(rf_res)
```


```{r}
collect_metrics(rf_res, summarize = FALSE) %>% 
  filter(.metric == "rmse") %>% 
  summarize(mean(.estimate))
```


```{r}
assess_res <- collect_predictions(rf_res, summarize = TRUE)
assess_res
```


```{r}
over_predicted <- 
  assess_res %>% 
  mutate(residual = Sale_Price - .pred) %>% 
  arrange(desc(abs(residual))) %>% 
  slice(1)
over_predicted
```


```{r}

ames_train %>% 
  slice(over_predicted$.row) %>% 
  select(Gr_Liv_Area, Neighborhood, Year_Built, Bedroom_AbvGr, Full_Bath)
```


```{r}
val_res <- rf_wflow %>% fit_resamples(resamples = val_set)
val_res
#> # Resampling results
#> # Validation Set Split (0.75/0.25)  
#> # A tibble: 1 x 4
#>   splits             id         .metrics         .notes          
#>   <list>             <chr>      <list>           <list>          
#> 1 <split [1.6K/549]> validation <tibble [2 × 4]> <tibble [0 × 1]>

collect_metrics(val_res)
#> # A tibble: 2 x 6
#>   .metric .estimator   mean     n std_err .config             
#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               
#> 1 rmse    standard   0.0668     1      NA Preprocessor1_Model1
#> 2 rsq     standard   0.859      1      NA Preprocessor1_Model1
```


```{r}
parallel::detectCores(logical = FALSE)
```


```{r}
#library(doMC)
#registerDoMC(cores = 2)
```


```{r}
# library(doParallel)
# cl <- makePSOCKcluster(8)
# registerDoParallel(cl)
```


```{r}
ames_rec <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + 
           Latitude + Longitude, data = ames_train) %>%
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal()) %>% 
  step_interact( ~ Gr_Liv_Area:starts_with("Bldg_Type_") ) %>% 
  step_ns(Latitude, Longitude, deg_free = 20)

lm_wflow <-  
  workflow() %>% 
  add_recipe(ames_rec) %>% 
  add_model(linear_reg() %>% set_engine("lm")) 

lm_fit <- lm_wflow %>% fit(data = ames_train)

# Select the recipe: 
pull_workflow_prepped_recipe(lm_fit)
```


```{r}
get_model <- function(x) {
  pull_workflow_fit(x) %>% tidy()
}
```


```{r}
ctrl <- control_resamples(extract = get_model)

lm_res <- lm_wflow %>%  fit_resamples(resamples = ames_folds, control = ctrl)
lm_res
```


```{r}
lm_res$.extracts[[1]]
```


```{r}
lm_res$.extracts[[1]][[1]]
```


```{r}
all_coef <- map_dfr(lm_res$.extracts, ~.x[[1]][[1]])
all_coef %>% 
  filter(term == "Year_Built")
```


```{r}
library(tidymodels)
data(ames)
ames <- mutate(ames, Sale_Price = log10(Sale_Price))

set.seed(123)
ames_split <- initial_split(ames, prob = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)

ames_rec <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + 
           Latitude + Longitude, data = ames_train) %>%
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal()) %>% 
  step_interact( ~ Gr_Liv_Area:starts_with("Bldg_Type_") ) %>% 
  step_ns(Latitude, Longitude, deg_free = 20)

lm_model <- linear_reg() %>% set_engine("lm")

lm_wflow <- 
  workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(ames_rec)

lm_fit <- fit(lm_wflow, ames_train)

rf_model <- 
  rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("regression")

rf_wflow <- 
  workflow() %>% 
  add_formula(
    Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + 
      Latitude + Longitude) %>% 
  add_model(rf_model) 

set.seed(55)
ames_folds <- vfold_cv(ames_train, v = 10)

keep_pred <- control_resamples(save_pred = TRUE)

set.seed(130)
rf_res <- rf_wflow %>% fit_resamples(resamples = ames_folds, control = keep_pred)
```


# 11 Comparing models with resampling

```{r}
lm_with_splines_res <-
  lm_wflow %>% 
  fit_resamples(resamples = ames_folds, control = keep_pred)
```


```{r}
no_spline_rec <-
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type +
           Latitude + Longitude, data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal()) %>% 
  step_interact(~Gr_LivArea:starts_with("Bldg_Type_"))

lm_no_splines_res <-
  lm_wflow %>% 
  remove_recipe() %>% 
  add_recipe(no_spline_rec) %>% 
  fit_resamples(resamples = ames_folds, control = keep_pred)
```


```{r}
collect_metrics(lm_no_splines_res)
```


```{r}
collect_metrics(lm_with_splines_res)
```


```{r}
no_splines_rsq <-
  collect_metrics(lm_no_splines_res, summarize = FALSE) %>% 
  filter(.metric == "rsq") %>% 
  select(id, `no splines` = .estimate)
no_splines_rsq
```


```{r}
splines_rsq <-
  collect_metrics(lm_with_splines_res, summarize = FALSE) %>% 
  filter(.metric == "rsq") %>% 
  select(id, `with splines` = .estimate)
splines_rsq
```


```{r}
rf_rsq <-
  collect_metrics(rf_res, summarize = FALSE) %>% 
  filter(.metric == "rsq") %>% 
  select(id, `random forest` = .estimate)
rf_rsq
```


```{r}
rsq_estimates <-
  no_splines_rsq %>% 
  inner_join(splines_rsq, by = "id") %>% 
  inner_join(rf_rsq, by = "id")
rsq_estimates
```


```{r}
rsq_estimates %>% 
  pivot_longer(c(-id), names_to = "model", values_to = "rsq") %>% 
  mutate(model = reorder(model, rsq)) %>% 
  ggplot(aes(model, rsq, group = id, col = id)) +
  geom_line(alpha = .5, lwd = 1.25) +
  theme(legend.position = "none") +
  labs(x = NULL, y = expression(paste(R^2, "statistics")))
```


```{r}
rsq_estimates %>% 
  with(cor.test(`no splines`, `random forest`)) %>% 
  tidy() %>% 
  select(estimate, starts_with("conf"))
```


```{r}
compare_lm <-
  rsq_estimates %>% 
  mutate(difference = `with splines` - `no splines`)
compare_lm
```


```{r}
lm(difference ~ 1, data = compare_lm) %>% 
  tidy(conf.int = TRUE) %>% 
  select(estimate, p.value, starts_with("conf"))
```


```{r}
rsq_estimates %>% 
  with(t.test(`with splines`, `no splines`, paired = TRUE)) %>% 
  tidy() %>% 
  select(estimate, p.value, starts_with("conf"))
```


```{r}
# Bring the R^2 values into the original rsample object:
ames_two_models <- 
  ames_folds %>% 
  bind_cols(rsq_estimates %>% arrange(id) %>% select(-id))

ames_two_models %>% slice(1:4)
#> # A tibble: 4 x 5
#>   splits           id     `no splines` `with splines` `random forest`
#>   <list>           <chr>         <dbl>          <dbl>           <dbl>
#> 1 <split [2K/220]> Fold01        0.845          0.857           0.885
#> 2 <split [2K/220]> Fold02        0.781          0.785           0.843
#> 3 <split [2K/220]> Fold03        0.740          0.756           0.793
#> 4 <split [2K/220]> Fold04        0.835          0.838           0.864
```


```{r}
library(tidyposterior)
library(rstanarm)

# The rstanarm package creates copious amounts of output; those results
# are not shown here but are worth inspecting for potential issues. 
rsq_anova <-
  perf_mod(
    ames_two_models,
    prior_intercept = student_t(df = 1),
    chains = 4,
    iter = 5000,
    seed = 2
  )
```


```{r}
model_post <- 
  rsq_anova %>% 
  # Take a random sample from the posterior distribution
  # so set the seed again to be reproducible. 
  tidy(seed = 35) %>% 
  as_tibble() 
#> Instead of posterior_linpred(..., transform=TRUE) please call posterior_epred(), which provides equivalent functionality.

glimpse(model_post)
#> Rows: 30,000
#> Columns: 2
#> $ model     <chr> "no splines", "no splines", "no splines", "no splines", "no spl…
#> $ posterior <dbl> 0.8096, 0.8073, 0.8115, 0.8179, 0.8131, 0.8114, 0.8077, 0.8077,…
```


```{r}
library(tidyverse)
model_post %>% 
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = posterior)) + 
  geom_histogram(bins = 50, col = "white", fill = "blue", alpha = 0.4) + 
  facet_wrap(~ model, ncol = 1) + 
  labs(x = expression(paste("Posterior for mean ", R^2)))
```


```{r}
rqs_diff <-
  contrast_models(rsq_anova,
                  list_1 = "with splines",
                  list_2 = "no splines",
                  seed = 36)
#> Instead of posterior_linpred(..., transform=TRUE) please call posterior_epred(), which provides equivalent functionality.
#> Instead of posterior_linpred(..., transform=TRUE) please call posterior_epred(), which provides equivalent functionality.

rqs_diff %>% 
  as_tibble() %>% 
  ggplot(aes(x = difference)) + 
  geom_vline(xintercept = 0, lty = 2) + 
  geom_histogram(bins = 50, col = "white", fill = "red", alpha = 0.4) + 
  labs(x = expression(paste("Posterior for mean difference in ", R^2, 
                            " (splines - no splines)")))
```


```{r}
summary(rqs_diff) %>% 
  select(-starts_with("pract"))
#> # A tibble: 1 x 6
#>   contrast                   probability    mean    lower  upper  size
#>   <chr>                            <dbl>   <dbl>    <dbl>  <dbl> <dbl>
#> 1 with splines vs no splines       0.853 0.00585 -0.00367 0.0151     0
```


```{r}
summary(rqs_diff, size = 0.02) %>% 
  select(contrast, starts_with("pract"))
#> # A tibble: 1 x 4
#>   contrast                   pract_neg pract_equiv pract_pos
#>   <chr>                          <dbl>       <dbl>     <dbl>
#> 1 with splines vs no splines         0       0.990    0.0097
```


```{r}
# stopCluster(cl)
```


